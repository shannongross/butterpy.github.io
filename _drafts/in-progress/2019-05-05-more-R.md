---
published: false

layout: post
title: "More R stuff"
date: 2019-05-05
description: A python lover's guide for getting started with R # Add post description (optional)
img:  R-intro.png # Add image post (optional)
fig-caption: Introduction to R programming
tags: [R, python, data science, machine learning, jupyter notebook, caret]
---
## Learning the basics of R
To begin, type in `library(tidyverse)`. This single line will load the core tidyverse (common packages you'll use in nearly any project).


* ggplot() creates a (blank) coordinate system. The geom functions argument adds data to it.
A **geom** is the geometrical object used to plot the data (e.g. bar geom, line geoms, boxplot geoms, point geom)

a dataframe is the same thing as a matrix except it can have vectors of different data types - in matrices they must all be the same class



#Common data types
**Relational data** for working with interrelated datasets
**Strings** regular expressions
**Factors** how R stores categorical data
**Dates and Times**

###Tibbles
Tibbles are dataframes that make life in R a bit easier (it's part of tidyverse).
- coerce a regular into a dataframe using `as_tibble(iris)`
- create a new tibble from some vectors using `tibble()`, for instance:

{% highlight ruby %}
tibble(
  a = 0:5,
  b = 3,
  c = 2a - b
  )
{% endhighlight %}

# Caret package
Caret (short for "Classification And REgression Training") does many of the common tasks of supervised learning for us.

{% highlight ruby %}
#import caret
library("caret")
{% endhighlight %}

Randomly split the data into 80% training and 20% reserved for resting.
- begin by setting a random seed (so that the process is reproducible)
- decide the type of algorithm you want to use (e.g. linear, logistic)
- "The first step is to split it into training(80%) and test(20%) datasets using caretâ€™s createDataPartition function.

The advantage of using createDataPartition() over the traditional random sample() is, it preserves the proportion of the categories in Y variable, that can be disturbed if you sample randomly.""


Now, we fit a linear model (`lm`) to the data using:
{% highlight ruby %}
model <- lm(price ~ ., diamonds)
p <- predict(model, diamonds)
{% endhighlight %}


# Logistic Regression
- The logistic function always results in an S-shaped curve
- **odds ratio** very low values (near zero) indicates low probability of X occurring. High values (near infinity) mean high values of p(X).
- the **logit** is the log of the odds ratio


## Imputing
When you have some missing values, you may want to fill them in or **impute** them. If the data is continuous, you might replace this blank with the mean of the column. If your variable is categorical, a strategy might be to replace it with the mode (most common) value. But a more thoughtful approach would to be to actually try and predict the missing value, which you could do using **k-Nearest Neighbors**.

In R, caret offers a `preProcess` function to calculate the k-Nearest Neighbor.



# Important ways that R is different than Python:
1. Don't name columns with spaces. Unlike with pandas, you can't get around this using single or double quotes. If you do name a column with a space, R won't throw up an error message to warn you, but you'll face many weird problems later on when you try to reference the column by name. Note that these problems also occur with many other special characters (including commas) so it's best to keep column names as simple and tidy as possible.
